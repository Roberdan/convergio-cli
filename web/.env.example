# ============================================================================
# CONVERGIO WEB - ENVIRONMENT CONFIGURATION
# Copy this file to .env.local and fill in your values
# ============================================================================

# ============================================================================
# AI PROVIDERS (Choose one for chat, Azure required for voice)
# ============================================================================

# Option 1: Azure OpenAI (Recommended for production)
# All Azure endpoints must be configured for full functionality
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# Voice Features (Azure OpenAI Realtime - REQUIRED for voice)
# Voice will not work without these - text chat fallback will be shown
AZURE_OPENAI_REALTIME_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_REALTIME_API_KEY=your-api-key
AZURE_OPENAI_REALTIME_DEPLOYMENT=gpt-4o-realtime-preview

# Option 2: Ollama (100% local, free, chat/text only)
# If Azure is not configured, the app will automatically try Ollama
# Voice features will NOT work with Ollama (realtime audio not supported)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ============================================================================
# AZURE COST MANAGEMENT (Optional - for cost tracking in Settings)
# ============================================================================

# To enable cost tracking, you need a Service Principal with "Cost Management Reader" role:
#
# 1. Create App Registration in Azure AD:
#    az ad app create --display-name "Convergio Cost Reader"
#
# 2. Create Service Principal:
#    az ad sp create --id <app-id>
#
# 3. Create client secret:
#    az ad app credential reset --id <app-id>
#
# 4. Assign "Cost Management Reader" role on subscription:
#    az role assignment create \
#      --assignee <service-principal-id> \
#      --role "Cost Management Reader" \
#      --scope /subscriptions/<subscription-id>

AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-service-principal-client-id
AZURE_CLIENT_SECRET=your-service-principal-secret
AZURE_SUBSCRIPTION_ID=your-subscription-id

# ============================================================================
# DATABASE
# ============================================================================

# SQLite for local development (default)
DATABASE_URL="file:./prisma/dev.db"

# PostgreSQL for production (uncomment and configure when deploying)
# DATABASE_URL="postgresql://user:password@host:5432/convergio?sslmode=require"

# ============================================================================
# PROVIDERS THAT ARE NEVER USED (listed for clarity)
# ============================================================================

# OPENAI_API_KEY=xxx        # DO NOT USE - Use Azure OpenAI instead
# ANTHROPIC_API_KEY=xxx     # DO NOT USE - Never use Anthropic

# ============================================================================
# DEPLOYMENT NOTES
# ============================================================================
#
# 1. For Vercel deployment:
#    - Add these variables in Project Settings > Environment Variables
#    - No need to upload .env.local file
#
# 2. For Docker deployment:
#    - Pass variables via --env-file or -e flags
#    - Example: docker run --env-file .env.local convergio-web
#
# 3. For local development:
#    - Copy this file: cp .env.example .env.local
#    - Fill in your Azure OpenAI credentials
#    - Run: npm run dev
#
# ============================================================================
# OLLAMA QUICK START (100% local, no cloud, chat only)
# ============================================================================
#
#   # Install Ollama
#   brew install ollama
#
#   # Start server (keep running in terminal)
#   ollama serve
#
#   # Pull a model (in another terminal)
#   ollama pull llama3.2        # Fast, good for education (~2GB)
#   # OR
#   ollama pull mistral         # Alternative (~4GB)
#   # OR
#   ollama pull llama3.1:70b    # Best quality (needs 64GB+ RAM)
#
#   # Then just run the webapp - it will auto-detect Ollama
#   # Note: Voice features require Azure OpenAI Realtime
#
# ============================================================================
