# ConvergioCLI v4.0.0 Release Plan

## Overview

Major release adding two new AI providers (OpenRouter, Ollama), interactive setup wizard, and guided configuration across multiple commands.

**Current Version:** 3.0.13
**Target Version:** 4.0.0
**Release Type:** Major (new features, no breaking changes)

---

## Features Summary

| # | Feature | Description | New File |
|---|---------|-------------|----------|
| 1 | OpenRouter Provider | Access to 300+ models via OpenAI-compatible API | `openrouter.c` |
| 2 | Ollama Provider | Local models with zero API costs | `ollama.c` |
| 3 | Setup Wizard | Interactive config for providers and agent models | `setup_wizard.c` |
| 4 | Project Wizard | Guided project creation with templates | (in setup_wizard.c) |
| 5 | Compare Wizard | Interactive model comparison setup | (in setup_wizard.c) |
| 6 | Budget Wizard | Guided budget configuration with presets | (in setup_wizard.c) |

---

## Parallelization Strategy

```
┌─────────────────────────────────────────────────────────────────┐
│                    PARALLEL WORKSTREAMS                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Stream A: Providers          Stream B: Wizards                 │
│  ─────────────────           ──────────────────                 │
│  1. provider.h (enum)        1. setup_wizard.c (base)          │
│  2. openrouter.c             2. project wizard                  │
│  3. ollama.c                 3. compare wizard                  │
│  4. provider.c (register)    4. budget wizard                   │
│  5. tools.c (cases)                                             │
│  6. streaming.c (parsers)                                       │
│                                                                 │
│  Stream C: Tests             Stream D: Config/Release           │
│  ──────────────────         ───────────────────────             │
│  1. mock_openrouter.c        1. models.json update             │
│  2. mock_ollama.c            2. Makefile update                │
│  3. E2E test updates         3. VERSION bump                   │
│  4. Unit test updates        4. CHANGELOG.md                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Detailed Feature List

### 1. OpenRouter Provider
Access to 300+ models via unified OpenAI-compatible API.

### 2. Ollama Provider
Local models with zero API costs.

### 3. Setup Wizard (`/setup`)
Main configuration wizard with:
- API Keys configuration (guided, with help text)
- Agent model selection (primary/fallback per agent)
- Quick Setup profiles (Budget/Balanced/Quality/Local)
- View current configuration

### 4. Project Wizard (`project create --wizard`)
Guided project creation:
- Template selection with descriptions
- Team member selection from available agents
- Purpose definition
- Auto-configuration based on template

### 5. Compare Wizard (`compare --wizard`)
Interactive model comparison:
- Select models from available list (filtered by API key availability)
- Choose comparison options
- Budget estimation before running

### 6. Budget Wizard (`cost setup`)
Guided budget configuration:
- Preset profiles (Conservative $1/day, Standard $5/day, Unlimited)
- Custom budget with cost estimation
- Warnings for high-cost operations

---

## Implementation Steps

### Step 1: Update provider.h

**File:** `include/nous/provider.h`

```c
typedef enum {
    PROVIDER_ANTHROPIC   = 0,
    PROVIDER_OPENAI      = 1,
    PROVIDER_GEMINI      = 2,
    PROVIDER_OPENROUTER  = 3,  // NEW
    PROVIDER_OLLAMA      = 4,  // NEW
    PROVIDER_COUNT       = 5
} ProviderType;

// New exports
Provider* openrouter_provider_create(void);
Provider* ollama_provider_create(void);
```

---

### Step 2: Create openrouter.c

**File:** `src/providers/openrouter.c` (~400 lines)

**Key characteristics:**
- Base URL: `https://openrouter.ai/api/v1`
- Auth: `Authorization: Bearer {OPENROUTER_API_KEY}`
- Required header: `HTTP-Referer: https://convergio.dev`
- 100% OpenAI-compatible format

**Functions:**
- `openrouter_init()` - Verify OPENROUTER_API_KEY
- `openrouter_shutdown()` - Cleanup
- `openrouter_validate_key()` - Check env var
- `openrouter_chat()` - Reuse OpenAI logic with different URL/headers
- `openrouter_chat_with_tools()` - OpenAI-style tool calling
- `openrouter_stream_chat()` - SSE streaming
- `openrouter_provider_create()` - Factory

---

### Step 3: Create ollama.c

**File:** `src/providers/ollama.c` (~350 lines)

**Key characteristics:**
- Base URL: `http://localhost:11434` (configurable via OLLAMA_HOST)
- Auth: None (local)
- Ollama API format

**Endpoints:**
- `POST /api/generate` - Text generation
- `POST /api/chat` - Chat with history
- `GET /api/tags` - List installed models

**Functions:**
- `ollama_init()` - Verify Ollama is running
- `ollama_shutdown()` - Cleanup
- `ollama_validate_key()` - Always true, but ping localhost
- `ollama_chat()` - POST /api/generate
- `ollama_stream_chat()` - Streaming with `"stream": true`
- `ollama_list_models()` - GET /api/tags
- `ollama_provider_create()` - Factory

---

### Step 4: Update provider.c

**File:** `src/providers/provider.c`

**Changes:**
1. Add `g_openrouter_models[]` array with DeepSeek, Mistral, Llama, Qwen
2. Add `g_ollama_models[]` array with llama3.2, mistral, codellama
3. Update `g_provider_names[]` and `g_provider_api_key_envs[]`
4. Register providers in `provider_registry_init()`
5. Add cases in `model_get_by_provider()`

---

### Step 5: Update tools.c

**File:** `src/providers/tools.c`

```c
case PROVIDER_OPENROUTER:
    return build_openai_tools_json(tools, count);  // Reuse OpenAI

case PROVIDER_OPENROUTER:
    return parse_openai_tool_calls(response, out_count);  // Reuse OpenAI
```

---

### Step 6: Update streaming.c

**File:** `src/providers/streaming.c`

```c
case PROVIDER_OPENROUTER:
    return parse_openai_sse_chunk(chunk, out_text);  // Same as OpenAI

case PROVIDER_OLLAMA:
    return parse_ollama_stream_chunk(chunk, out_text);  // New parser
```

---

### Step 7: Create setup_wizard.c

**File:** `src/core/commands/setup_wizard.c` (~500 lines)

**Main Menu:**
1. API Keys - Configure provider credentials
2. Agent Models - Set primary/fallback models per agent
3. Quick Setup - Guided setup with profiles
4. View Config - Show current configuration
5. Exit

**Quick Setup Profiles:**
- Budget-Friendly (GPT-4.1-mini, Gemini Flash)
- Balanced (Sonnet 4.5, GPT-5.2)
- Maximum Quality (Opus 4.5, o3, GPT-5.2-Pro)
- Local-First (Ollama with cloud fallback)

**Persistence:** `~/.convergio/agent_models.json`

---

### Step 8: Update config/models.json

Add OpenRouter and Ollama sections:

```json
{
  "providers": {
    "openrouter": {
      "name": "OpenRouter",
      "api_key_env": "OPENROUTER_API_KEY",
      "base_url": "https://openrouter.ai/api/v1",
      "models": {
        "deepseek/deepseek-r1": {...},
        "mistralai/mistral-large-2411": {...},
        "meta-llama/llama-3.3-70b-instruct": {...},
        "qwen/qwen-2.5-72b-instruct": {...}
      }
    },
    "ollama": {
      "name": "Ollama (Local)",
      "api_key_env": null,
      "base_url": "http://localhost:11434",
      "models": {
        "llama3.2": {...},
        "mistral": {...},
        "codellama": {...}
      }
    }
  }
}
```

---

### Step 9: Update Makefile

```makefile
PROVIDER_SRCS = src/providers/provider.c \
                src/providers/anthropic.c \
                src/providers/openai.c \
                src/providers/gemini.c \
                src/providers/openrouter.c \
                src/providers/ollama.c \
                ...
```

---

### Step 10: Create Mock Providers for Tests

**Files:**
- `tests/mocks/mock_openrouter.c`
- `tests/mocks/mock_ollama.c`

Pattern: Same as existing mock_anthropic.c, mock_openai.c, mock_gemini.c

---

### Step 11: Update E2E Tests

**File:** `tests/e2e_test.sh`

Add new test sections:

```bash
# =============================================================================
# SECTION: OpenRouter Provider Tests
# =============================================================================
echo -e "${BLUE}=== Section: OpenRouter Provider ===${NC}"

run_test "openrouter provider registered" "status" "openrouter"
run_test "openrouter models listed" "help" "deepseek"

# Only run API tests if key is set
if [ -n "$OPENROUTER_API_KEY" ]; then
    run_test "openrouter chat" "@ali What is 2+2? Use openrouter/deepseek/deepseek-r1" "4"
else
    skip_test "openrouter API call" "OPENROUTER_API_KEY not set"
fi

# =============================================================================
# SECTION: Ollama Provider Tests
# =============================================================================
echo -e "${BLUE}=== Section: Ollama Provider ===${NC}"

run_test "ollama provider registered" "status" "ollama"

# Only run if Ollama is running
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    run_test "ollama connection" "status" "ollama.*OK\|ollama.*Local"
    run_test "ollama chat" "@marco What is 2+2? Use ollama/llama3.2" "4"
else
    skip_test "ollama connection" "Ollama not running"
    skip_test "ollama chat" "Ollama not running"
fi

# =============================================================================
# SECTION: Setup Wizard Tests
# =============================================================================
echo -e "${BLUE}=== Section: Setup Wizard ===${NC}"

run_test "setup command exists" "help" "setup"
run_test_no_error "setup menu displays" "setup\n5"
run_test "setup shows providers" "setup\n1\n0\n5" "Anthropic\|OpenAI\|OpenRouter\|Ollama"
run_test "setup shows agents" "setup\n2\n0\n5" "Ali\|Marco\|Baccio"
```

---

### Step 12: Update Unit Tests

**File:** `tests/unit/test_model_router.c`

Add tests for new providers:

```c
void test_openrouter_model_lookup(void) {
    const ModelConfig* config = model_get_config("openrouter/deepseek/deepseek-r1");
    TEST_ASSERT_NOT_NULL(config);
    TEST_ASSERT_EQUAL(PROVIDER_OPENROUTER, config->provider);
}

void test_ollama_model_lookup(void) {
    const ModelConfig* config = model_get_config("ollama/llama3.2");
    TEST_ASSERT_NOT_NULL(config);
    TEST_ASSERT_EQUAL(PROVIDER_OLLAMA, config->provider);
    TEST_ASSERT_EQUAL(0.0, config->input_cost_per_mtok);  // Free
}

void test_agent_fallback_to_openrouter(void) {
    // Configure agent with OpenRouter fallback
    router_set_agent_model("test_agent", "openrouter/deepseek/deepseek-r1", false);

    // Simulate primary failure
    ModelSelection sel = router_select_model_for_agent("test_agent", 10.0);

    // Should fallback to OpenRouter
    TEST_ASSERT_STRING_CONTAINS("openrouter", sel.model_id);
}
```

---

### Step 13: Update Integration Tests

**File:** `tests/integration/test_multi_provider.c`

Add OpenRouter and Ollama integration tests.

---

### Step 14: Version Bump

**Files to update:**
- `VERSION`: `4.0.0`
- `CHANGELOG.md`: Add v4.0.0 section
- `src/core/main.c`: Update version string if hardcoded

---

### Step 15: Release Checklist

Before release, app-release-manager will verify:

- [ ] All tests pass (`make test`)
- [ ] E2E tests pass (`./tests/e2e_test.sh`)
- [ ] No security vulnerabilities
- [ ] Documentation updated
- [ ] CHANGELOG.md updated
- [ ] VERSION bumped to 4.0.0
- [ ] No uncommitted changes
- [ ] Build succeeds on clean checkout
- [ ] Homebrew formula ready

---

## File Summary

### New Files
| File | Lines | Description |
|------|-------|-------------|
| `src/providers/openrouter.c` | ~400 | OpenRouter adapter |
| `src/providers/ollama.c` | ~350 | Ollama adapter |
| `src/core/commands/setup_wizard.c` | ~500 | Interactive wizard |
| `tests/mocks/mock_openrouter.c` | ~150 | Test mock |
| `tests/mocks/mock_ollama.c` | ~150 | Test mock |

### Modified Files
| File | Changes |
|------|---------|
| `include/nous/provider.h` | +enum, +exports |
| `src/providers/provider.c` | +registration, +models |
| `src/providers/tools.c` | +cases for new providers |
| `src/providers/streaming.c` | +SSE parsers |
| `src/core/commands/commands.c` | +setup command |
| `config/models.json` | +openrouter, +ollama sections |
| `Makefile` | +new source files |
| `tests/e2e_test.sh` | +new test sections |
| `tests/unit/test_model_router.c` | +provider tests |
| `VERSION` | 3.0.13 → 4.0.0 |
| `CHANGELOG.md` | +v4.0.0 section |

---

## Additional Wizard Implementations

### Project Wizard (in setup_wizard.c)

Add `--wizard` flag to `project create`:

```c
// When user runs: project create --wizard
void project_creation_wizard(void) {
    clear_screen();
    print_header("PROJECT CREATION WIZARD");

    // Step 1: Choose template or custom
    printf("\n  How would you like to create your project?\n\n");
    printf("    1) Use a template (recommended)\n");
    printf("    2) Custom configuration\n");

    // Step 2: If template, show template list with descriptions
    // Step 3: Select/customize team members
    // Step 4: Define purpose
    // Step 5: Confirm and create
}
```

### Compare Wizard (in setup_wizard.c)

Add `--wizard` flag to `compare`:

```c
// When user runs: compare --wizard
void compare_wizard(void) {
    clear_screen();
    print_header("MODEL COMPARISON WIZARD");

    // Step 1: Enter prompt
    printf("\n  Enter the prompt to test:\n  > ");

    // Step 2: Select models (show only available ones)
    printf("\n  Select models to compare (space to toggle, enter to confirm):\n");
    // Show checkboxes with cost estimates

    // Step 3: Options
    printf("\n  Options:\n");
    printf("    [ ] Show diff between responses\n");
    printf("    [ ] Output as JSON\n");

    // Step 4: Cost estimate and confirm
    printf("\n  Estimated cost: $0.05\n");
    printf("  Proceed? [Y/n]: ");
}
```

### Budget Wizard (in setup_wizard.c)

Add `setup` subcommand to `cost`:

```c
// When user runs: cost setup
void budget_wizard(void) {
    clear_screen();
    print_header("BUDGET CONFIGURATION");

    printf("\n  Choose a budget profile:\n\n");
    printf("    1) Conservative   - $1.00/day  (basic tasks, testing)\n");
    printf("    2) Standard       - $5.00/day  (daily development)\n");
    printf("    3) Professional   - $20.00/day (heavy usage)\n");
    printf("    4) Unlimited      - No limit   (enterprise)\n");
    printf("    5) Custom         - Set your own limit\n");

    // After selection, configure:
    // - Daily limit
    // - Session limit
    // - Warning threshold (80% default)
    // - Auto-downgrade behavior
}
```

---

## Updated File Summary

### New Files
| File | Lines | Description |
|------|-------|-------------|
| `src/providers/openrouter.c` | ~400 | OpenRouter adapter |
| `src/providers/ollama.c` | ~350 | Ollama adapter |
| `src/core/commands/setup_wizard.c` | ~800 | All wizards (setup + project + compare + budget) |
| `tests/mocks/mock_openrouter.c` | ~150 | Test mock |
| `tests/mocks/mock_ollama.c` | ~150 | Test mock |

---

## Estimated Effort

| Component | Lines |
|-----------|-------|
| openrouter.c | ~400 |
| ollama.c | ~350 |
| setup_wizard.c (all wizards) | ~800 |
| Mocks | ~300 |
| Tests | ~250 |
| Config/Other | ~150 |
| **Total** | **~2250** |

---

## Environment Variables

```bash
# Required for OpenRouter
OPENROUTER_API_KEY=sk-or-v1-...

# Optional for Ollama (custom host)
OLLAMA_HOST=http://localhost:11434
```

---

## Notes

1. **OpenRouter** requires `HTTP-Referer` header - without it requests fail
2. **Ollama** must be running locally - graceful error if not available
3. OpenRouter model IDs include original provider: `anthropic/claude-3-opus`
4. Ollama doesn't support tool calling natively - `supports_tools = false`
5. Ollama costs = 0 (local) - excellent for testing and development
6. Setup wizard saves to `~/.convergio/agent_models.json`
7. Wizard profiles auto-configure all 49 agents based on role
