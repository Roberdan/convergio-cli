{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "version": "2025.12.4",
  "last_updated": "2025-12-13T10:00:00Z",
  "update_url": "https://raw.githubusercontent.com/Roberdan/convergio-cli/main/config/models.json",
  "providers": {
    "anthropic": {
      "name": "Anthropic",
      "api_key_env": "ANTHROPIC_API_KEY",
      "base_url": "https://api.anthropic.com/v1",
      "docs_url": "https://docs.anthropic.com",
      "pricing_url": "https://www.anthropic.com/pricing",
      "models": {
        "claude-opus-4.5": {
          "display_name": "Claude Opus 4.5",
          "api_id": "claude-opus-4-5-20251101",
          "input_cost": 15.0,
          "output_cost": 75.0,
          "context_window": 200000,
          "max_output": 32000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "premium",
          "released": "2025-11-24",
          "deprecated": false,
          "best_for": ["complex reasoning", "autonomous agents", "enterprise workflows"]
        },
        "claude-sonnet-4.5": {
          "display_name": "Claude Sonnet 4.5",
          "api_id": "claude-sonnet-4-5-20250929",
          "input_cost": 3.0,
          "output_cost": 15.0,
          "context_window": 1000000,
          "max_output": 64000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-09-29",
          "deprecated": false,
          "best_for": ["coding", "agents", "computer use", "long context"]
        },
        "claude-opus-4": {
          "display_name": "Claude Opus 4",
          "api_id": "claude-opus-4-20250522",
          "input_cost": 15.0,
          "output_cost": 75.0,
          "context_window": 200000,
          "max_output": 32000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "premium",
          "released": "2025-05-22",
          "deprecated": false,
          "best_for": ["complex reasoning", "deep analysis"]
        },
        "claude-sonnet-4": {
          "display_name": "Claude Sonnet 4",
          "api_id": "claude-sonnet-4-20250522",
          "input_cost": 3.0,
          "output_cost": 15.0,
          "context_window": 200000,
          "max_output": 64000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-05-22",
          "deprecated": false,
          "best_for": ["general purpose", "balanced performance"]
        }
      }
    },
    "openai": {
      "name": "OpenAI",
      "api_key_env": "OPENAI_API_KEY",
      "base_url": "https://api.openai.com/v1",
      "docs_url": "https://platform.openai.com/docs",
      "pricing_url": "https://openai.com/api/pricing",
      "models": {
        "gpt-5.2": {
          "display_name": "GPT-5.2 Thinking",
          "api_id": "gpt-5.2",
          "input_cost": 1.75,
          "output_cost": 14.0,
          "context_window": 400000,
          "max_output": 128000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-12-11",
          "deprecated": false,
          "best_for": ["coding", "analysis", "math", "planning", "long documents"]
        },
        "gpt-5.2-pro": {
          "display_name": "GPT-5.2 Pro",
          "api_id": "gpt-5.2-pro",
          "input_cost": 5.0,
          "output_cost": 30.0,
          "context_window": 400000,
          "max_output": 128000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "premium",
          "released": "2025-12-11",
          "deprecated": false,
          "best_for": ["maximum accuracy", "difficult problems", "enterprise"]
        },
        "gpt-5.2-instant": {
          "display_name": "GPT-5.2 Instant",
          "api_id": "gpt-5.2-chat-latest",
          "input_cost": 0.50,
          "output_cost": 2.0,
          "context_window": 400000,
          "max_output": 128000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2025-12-11",
          "deprecated": false,
          "best_for": ["fast responses", "routine queries", "cost-effective"]
        },
        "gpt-5-codex": {
          "display_name": "GPT-5 Codex",
          "api_id": "gpt-5-codex",
          "input_cost": 2.0,
          "output_cost": 10.0,
          "context_window": 200000,
          "max_output": 64000,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-08-07",
          "deprecated": false,
          "best_for": ["code generation", "debugging", "refactoring", "Codex CLI"]
        },
        "o3": {
          "display_name": "o3",
          "api_id": "o3",
          "input_cost": 10.0,
          "output_cost": 40.0,
          "context_window": 200000,
          "max_output": 100000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "premium",
          "released": "2025-04-16",
          "deprecated": false,
          "best_for": ["deep reasoning", "complex analysis", "math", "coding"]
        },
        "o3-mini": {
          "display_name": "o3-mini",
          "api_id": "o3-mini",
          "input_cost": 1.10,
          "output_cost": 4.40,
          "context_window": 200000,
          "max_output": 100000,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-01-31",
          "deprecated": false,
          "best_for": ["fast reasoning", "coding", "math"]
        },
        "o4-mini": {
          "display_name": "o4-mini",
          "api_id": "o4-mini",
          "input_cost": 1.10,
          "output_cost": 4.40,
          "context_window": 200000,
          "max_output": 100000,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-04-16",
          "deprecated": false,
          "best_for": ["fast reasoning", "visual tasks", "coding"]
        },
        "gpt-4.1": {
          "display_name": "GPT-4.1",
          "api_id": "gpt-4.1",
          "input_cost": 2.0,
          "output_cost": 8.0,
          "context_window": 1000000,
          "max_output": 32768,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-04-14",
          "deprecated": false,
          "best_for": ["general purpose", "multimodal", "long context"]
        },
        "gpt-4.1-mini": {
          "display_name": "GPT-4.1 mini",
          "api_id": "gpt-4.1-mini",
          "input_cost": 0.40,
          "output_cost": 1.60,
          "context_window": 1000000,
          "max_output": 32768,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2025-04-14",
          "deprecated": false,
          "best_for": ["cost-effective", "simple tasks", "high volume"]
        },
        "gpt-4.1-nano": {
          "display_name": "GPT-4.1 nano",
          "api_id": "gpt-4.1-nano",
          "input_cost": 0.10,
          "output_cost": 0.40,
          "context_window": 1000000,
          "max_output": 32768,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2025-04-14",
          "deprecated": false,
          "best_for": ["routing", "classification", "ultra-low cost"]
        }
      }
    },
    "gemini": {
      "name": "Google Gemini",
      "api_key_env": "GOOGLE_API_KEY",
      "base_url": "https://generativelanguage.googleapis.com/v1beta",
      "docs_url": "https://ai.google.dev/docs",
      "pricing_url": "https://ai.google.dev/pricing",
      "models": {
        "gemini-3.0-pro": {
          "display_name": "Gemini 3.0 Pro",
          "api_id": "gemini-3.0-pro",
          "input_cost": 1.25,
          "output_cost": 5.0,
          "context_window": 2000000,
          "max_output": 8192,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2025-11-18",
          "deprecated": false,
          "best_for": ["long context", "document analysis", "research"]
        },
        "gemini-3.0-deep-think": {
          "display_name": "Gemini 3.0 Deep Think",
          "api_id": "gemini-3.0-deep-think",
          "input_cost": 5.0,
          "output_cost": 20.0,
          "context_window": 1000000,
          "max_output": 32768,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "premium",
          "released": "2025-12-04",
          "deprecated": false,
          "best_for": ["deep reasoning", "complex analysis", "research"]
        },
        "gemini-2.0-flash": {
          "display_name": "Gemini 2.0 Flash",
          "api_id": "gemini-2.0-flash",
          "input_cost": 0.10,
          "output_cost": 0.40,
          "context_window": 1000000,
          "max_output": 8192,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2025-01-30",
          "deprecated": false,
          "best_for": ["fast responses", "cost-effective", "agentic tasks"]
        }
      }
    },
    "openrouter": {
      "name": "OpenRouter",
      "api_key_env": "OPENROUTER_API_KEY",
      "base_url": "https://openrouter.ai/api/v1",
      "docs_url": "https://openrouter.ai/docs",
      "pricing_url": "https://openrouter.ai/docs#models",
      "notes": "OpenRouter provides access to 300+ models via unified API. Model IDs include provider prefix.",
      "models": {
        "deepseek/deepseek-r1": {
          "display_name": "DeepSeek R1",
          "api_id": "deepseek/deepseek-r1",
          "input_cost": 0.55,
          "output_cost": 2.19,
          "context_window": 64000,
          "max_output": 8192,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2025-01-20",
          "deprecated": false,
          "best_for": ["reasoning", "coding", "math", "budget-friendly"]
        },
        "mistralai/mistral-large-2411": {
          "display_name": "Mistral Large",
          "api_id": "mistralai/mistral-large-2411",
          "input_cost": 2.0,
          "output_cost": 6.0,
          "context_window": 128000,
          "max_output": 32768,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "mid",
          "released": "2024-11-15",
          "deprecated": false,
          "best_for": ["multilingual", "european", "GDPR compliant"]
        },
        "meta-llama/llama-3.3-70b-instruct": {
          "display_name": "Llama 3.3 70B",
          "api_id": "meta-llama/llama-3.3-70b-instruct",
          "input_cost": 0.40,
          "output_cost": 0.40,
          "context_window": 131072,
          "max_output": 16384,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2024-12-06",
          "deprecated": false,
          "best_for": ["open-source", "general purpose", "cost-effective"]
        },
        "qwen/qwen-2.5-72b-instruct": {
          "display_name": "Qwen 2.5 72B",
          "api_id": "qwen/qwen-2.5-72b-instruct",
          "input_cost": 0.35,
          "output_cost": 0.40,
          "context_window": 131072,
          "max_output": 16384,
          "supports_tools": true,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2024-09-19",
          "deprecated": false,
          "best_for": ["multilingual", "chinese", "coding", "math"]
        },
        "google/gemini-flash-1.5": {
          "display_name": "Gemini Flash 1.5 (via OR)",
          "api_id": "google/gemini-flash-1.5",
          "input_cost": 0.075,
          "output_cost": 0.30,
          "context_window": 1000000,
          "max_output": 8192,
          "supports_tools": true,
          "supports_vision": true,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2024-05-14",
          "deprecated": false,
          "best_for": ["ultra-cheap", "fast", "vision", "high volume"]
        }
      }
    },
    "ollama": {
      "name": "Ollama (Local)",
      "api_key_env": null,
      "base_url": "http://localhost:11434",
      "docs_url": "https://ollama.ai/docs",
      "pricing_url": null,
      "notes": "Ollama runs models locally. No API costs. Requires Ollama installed and running.",
      "models": {
        "llama3.2": {
          "display_name": "Llama 3.2 (Local)",
          "api_id": "llama3.2",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2024-09-25",
          "deprecated": false,
          "best_for": ["offline", "privacy", "no-cost", "testing"]
        },
        "mistral": {
          "display_name": "Mistral 7B (Local)",
          "api_id": "mistral",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 32768,
          "max_output": 4096,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2023-09-27",
          "deprecated": false,
          "best_for": ["lightweight", "fast local", "european"]
        },
        "codellama": {
          "display_name": "Code Llama (Local)",
          "api_id": "codellama",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 16384,
          "max_output": 4096,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2023-08-24",
          "deprecated": false,
          "best_for": ["coding", "offline", "no-cost"]
        },
        "deepseek-coder-v2": {
          "display_name": "DeepSeek Coder V2 (Local)",
          "api_id": "deepseek-coder-v2",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 128000,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2024-06-17",
          "deprecated": false,
          "best_for": ["coding", "large context", "local"]
        },
        "phi3": {
          "display_name": "Phi-3 (Local)",
          "api_id": "phi3",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 128000,
          "max_output": 4096,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "released": "2024-04-23",
          "deprecated": false,
          "best_for": ["small", "fast", "efficient", "reasoning"]
        }
      }
    },
    "mlx": {
      "name": "MLX (Apple Silicon Native)",
      "api_key_env": null,
      "base_url": "local://mlx",
      "docs_url": "https://github.com/ml-explore/mlx",
      "pricing_url": null,
      "notes": "MLX runs models natively on Apple Silicon Neural Engine. 100% offline, 100% free. Requires Apple Silicon Mac.",
      "models": {
        "llama-3.2-1b": {
          "display_name": "Llama 3.2 1B",
          "api_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 800,
          "min_ram_gb": 4,
          "released": "2024-09-25",
          "deprecated": false,
          "best_for": ["fast", "lightweight", "general purpose", "offline"]
        },
        "llama-3.2-3b": {
          "display_name": "Llama 3.2 3B",
          "api_id": "mlx-community/Llama-3.2-3B-Instruct-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 1800,
          "min_ram_gb": 8,
          "released": "2024-09-25",
          "deprecated": false,
          "best_for": ["balanced", "general purpose", "offline"]
        },
        "deepseek-r1-1.5b": {
          "display_name": "DeepSeek R1 Distill 1.5B",
          "api_id": "mlx-community/DeepSeek-R1-Distill-Qwen-1.5B-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 1000,
          "min_ram_gb": 4,
          "released": "2025-01-20",
          "deprecated": false,
          "best_for": ["reasoning", "coding", "math", "fast", "offline"]
        },
        "deepseek-r1-7b": {
          "display_name": "DeepSeek R1 Distill 7B",
          "api_id": "mlx-community/DeepSeek-R1-Distill-Qwen-7B-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 4500,
          "min_ram_gb": 8,
          "released": "2025-01-20",
          "deprecated": false,
          "best_for": ["reasoning", "coding", "math", "balanced", "offline"]
        },
        "deepseek-r1-14b": {
          "display_name": "DeepSeek R1 Distill 14B",
          "api_id": "mlx-community/DeepSeek-R1-Distill-Qwen-14B-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 8500,
          "min_ram_gb": 16,
          "released": "2025-01-20",
          "deprecated": false,
          "best_for": ["reasoning", "coding", "math", "quality", "offline"]
        },
        "qwen2.5-coder-7b": {
          "display_name": "Qwen 2.5 Coder 7B",
          "api_id": "mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 4200,
          "min_ram_gb": 8,
          "released": "2024-09-19",
          "deprecated": false,
          "best_for": ["coding", "code generation", "debugging", "offline"]
        },
        "phi-3-mini": {
          "display_name": "Phi-3 Mini",
          "api_id": "mlx-community/Phi-3-mini-4k-instruct-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 4096,
          "max_output": 2048,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 2200,
          "min_ram_gb": 6,
          "released": "2024-04-23",
          "deprecated": false,
          "best_for": ["fast", "efficient", "reasoning", "offline"]
        },
        "mistral-7b-q4": {
          "display_name": "Mistral 7B Q4",
          "api_id": "mlx-community/Mistral-7B-Instruct-v0.3-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 32768,
          "max_output": 4096,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 4100,
          "min_ram_gb": 8,
          "released": "2024-05-22",
          "deprecated": false,
          "best_for": ["multilingual", "european", "balanced", "offline"]
        },
        "llama-3.1-8b-q4": {
          "display_name": "Llama 3.1 8B Q4",
          "api_id": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
          "input_cost": 0.0,
          "output_cost": 0.0,
          "context_window": 131072,
          "max_output": 8192,
          "supports_tools": false,
          "supports_vision": false,
          "supports_streaming": true,
          "tier": "cheap",
          "size_mb": 4600,
          "min_ram_gb": 8,
          "released": "2024-07-23",
          "deprecated": false,
          "best_for": ["general purpose", "long context", "balanced", "offline"]
        }
      }
    }
  },
  "agent_defaults": {
    "ali": {
      "primary": "anthropic/claude-opus-4.5",
      "fallback": "openai/gpt-5.2-pro",
      "reason": "Chief of Staff needs best reasoning for delegation"
    },
    "baccio": {
      "primary": "anthropic/claude-opus-4.5",
      "fallback": "openai/gpt-5.2-pro",
      "reason": "Architecture requires deep reasoning and planning"
    },
    "marco": {
      "primary": "anthropic/claude-sonnet-4.5",
      "fallback": "openai/gpt-5-codex",
      "reason": "Sonnet 4.5 for coding, GPT-5-Codex as specialized fallback"
    },
    "luca": {
      "primary": "openai/o3",
      "fallback": "anthropic/claude-opus-4.5",
      "reason": "o3 excels at deep reasoning for security analysis"
    },
    "thor": {
      "primary": "openai/gpt-5.2-instant",
      "fallback": "gemini/gemini-2.0-flash",
      "reason": "Fast, cheap for quick reviews"
    },
    "nina": {
      "primary": "gemini/gemini-3.0-pro",
      "fallback": "openai/gpt-5.2",
      "reason": "Gemini's 2M context for data analysis"
    },
    "router": {
      "primary": "openai/gpt-5.2-instant",
      "fallback": "gemini/gemini-2.0-flash",
      "reason": "Fast and cheap for routing decisions"
    }
  },
  "compare_defaults": {
    "description": "Default models for /compare command (most powerful from each provider)",
    "models": ["claude-opus-4.5", "gpt-5.2"],
    "rationale": "Most capable models from Anthropic and OpenAI as of December 2025"
  },
  "benchmark_defaults": {
    "model": "claude-haiku-4.5",
    "iterations": 3
  },
  "cost_tiers": {
    "premium": {
      "description": "Most capable models for complex tasks",
      "max_input_cost": 20.0,
      "max_output_cost": 80.0,
      "use_cases": ["architecture", "security analysis", "complex reasoning"]
    },
    "mid": {
      "description": "Balanced performance and cost",
      "max_input_cost": 5.0,
      "max_output_cost": 20.0,
      "use_cases": ["coding", "general tasks", "document processing"]
    },
    "cheap": {
      "description": "Fast and cost-effective",
      "max_input_cost": 1.0,
      "max_output_cost": 5.0,
      "use_cases": ["classification", "routing", "simple tasks"]
    }
  }
}
